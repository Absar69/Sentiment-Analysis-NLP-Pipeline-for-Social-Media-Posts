{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885f325b-c271-4f3c-9268-b9b3d42dfd15",
   "metadata": {},
   "source": [
    "# Title: Development of an Automatic Sentiment Analysis Tool for Urdu Text on Social Media Platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4832c-9c1a-492b-9dea-1b57d2af9c59",
   "metadata": {},
   "source": [
    "# Phase 1: Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55b416-665d-4aa3-aab6-d1ad98bf11c0",
   "metadata": {},
   "source": [
    "# Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbb8b5c0-de15-4f63-a298-4727723ec0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lughaatNLP in /Applications/anaconda3/lib/python3.11/site-packages (1.0.6)\n",
      "Requirement already satisfied: python-Levenshtein in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (0.26.0)\n",
      "Requirement already satisfied: tensorflow in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (2.16.1)\n",
      "Requirement already satisfied: numpy in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (1.4.2)\n",
      "Requirement already satisfied: scipy in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (1.11.4)\n",
      "Requirement already satisfied: gtts in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (2.5.3)\n",
      "Requirement already satisfied: SpeechRecognition in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (3.10.4)\n",
      "Requirement already satisfied: pydub in /Applications/anaconda3/lib/python3.11/site-packages (from lughaatNLP) (0.25.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Applications/anaconda3/lib/python3.11/site-packages (from gtts->lughaatNLP) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Applications/anaconda3/lib/python3.11/site-packages (from gtts->lughaatNLP) (8.1.7)\n",
      "Requirement already satisfied: Levenshtein==0.26.0 in /Applications/anaconda3/lib/python3.11/site-packages (from python-Levenshtein->lughaatNLP) (0.26.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Applications/anaconda3/lib/python3.11/site-packages (from Levenshtein==0.26.0->python-Levenshtein->lughaatNLP) (3.10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn->lughaatNLP) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn->lughaatNLP) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Applications/anaconda3/lib/python3.11/site-packages (from SpeechRecognition->lughaatNLP) (4.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow->lughaatNLP) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->lughaatNLP) (0.41.2)\n",
      "Requirement already satisfied: rich in /Applications/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->lughaatNLP) (13.3.5)\n",
      "Requirement already satisfied: namex in /Applications/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->lughaatNLP) (0.0.8)\n",
      "Requirement already satisfied: optree in /Applications/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->lughaatNLP) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts->lughaatNLP) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts->lughaatNLP) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts->lughaatNLP) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts->lughaatNLP) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->lughaatNLP) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->lughaatNLP) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->lughaatNLP) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Applications/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow->lughaatNLP) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow->lughaatNLP) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Applications/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow->lughaatNLP) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Applications/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow->lughaatNLP) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lughaatNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "370effc1-471c-4a16-bc4b-07e2a5cc043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from LughaatNLP import LughaatNLP\n",
    "textProcessor = LughaatNLP()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1b8ed-9854-460e-b755-0fb613e6960c",
   "metadata": {},
   "source": [
    "# Step 2: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67d450d9-97b7-41f1-a8df-36829189a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            urdu_text  is_sarcastic  \\\n",
      "0   🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...           1.0   \n",
      "1   چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...           1.0   \n",
      "2   کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...           0.0   \n",
      "3                                        نہیں پائین 😎           0.0   \n",
      "4    `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...           1.0   \n",
      "5         قابل اعتبار ہی اکثر قاتل اعتبار ہوتے ہیں 💔🔥           1.0   \n",
      "6       انساں کو تھکا دیتا ہے سوچوں کا سفر بھی ... 🍁🥀           0.0   \n",
      "7                               حامد میر صاحب ویلڈن👏😊           0.0   \n",
      "8   یار وچارہ ویلا ہوندا ہے اس آرے لگا ہویا ہے😂😂 ت...           1.0   \n",
      "9            یہ سمجھتے ہیں سارا پاکستان بیوقوف ھے 😂😂😂           1.0   \n",
      "10                      تسی لڑاںٔی کروانی ساڈی کی 😂😂😂           0.0   \n",
      "11                       پائن دوبارہ فالو کرئیے..؟؟😆🙄           0.0   \n",
      "12  کتنی مہنگائی ہے الو دوسو روپے درجن کدو 80روپے ...           1.0   \n",
      "13   😍عشق جب تم کو راس آۓ گا 💔زخم کھاٶ گے 😊مُسکراٶ گے           1.0   \n",
      "14                                چونا ایسا ہی ہوتا 😂           0.0   \n",
      "15  خاتم_النبیین_محمدﷺ Surat 73 سورة المزمل Ayt 20...           0.0   \n",
      "16  اب بس بھی کرو بیچارے کی پہلے ہی دو بیویاں ہیے ...           1.0   \n",
      "17  پتہ نہیں کیا ہورہا ہے سی سی کی بورڈ کو زنگ لگ ...           1.0   \n",
      "18  اللہ آپ کو اپنی رحمتوں کے سائے میں رکھے اور مک...           0.0   \n",
      "19  آرمی چیف کا نوٹس۔ اب مجرم اپنے جرائیم پر خود ن...           0.0   \n",
      "\n",
      "    Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5 Unnamed: 6  Unnamed: 7  \n",
      "0          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "1          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "2          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "3          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "4          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "5          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "6          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "7          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "8          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "9          NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "10         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "11         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "12         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "13         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "14         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "15         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "16         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "17         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "18         NaN         NaN         NaN         NaN        NaN         NaN  \n",
      "19         NaN         NaN         NaN         NaN        NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_frame = pd.read_csv('urdu_sarcastic_dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data_frame.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2233d84-ef4a-46b7-b9f3-a8cd91235bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /Applications/anaconda3/lib/python3.11/site-packages (2.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbf726-09c2-44fe-85e1-d2100439b716",
   "metadata": {},
   "source": [
    "# Step 3: Stopwords removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2703ade8-c66b-4b2e-93eb-e0e1e89ad1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data After Stopword Removal:\n",
      "                                           urdu_text  \\\n",
      "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...   \n",
      "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...   \n",
      "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
      "3                                       نہیں پائین 😎   \n",
      "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...   \n",
      "\n",
      "                                               clean  \n",
      "0                 🤣😂😂 لینے شادی فسادن ٹھیک کوجی 😐😐😐🤣  \n",
      "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں😂😂  \n",
      "2  کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...  \n",
      "3                                            پائین 😎  \n",
      "4       `` مراد علی شاہ بھیس ڈی آئی آئی '' حامد میر😁  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentiment_carrying_stopwords = [\"نہیں\", \"برا\", \"واہ\", \"بہت\"]\n",
    "\n",
    "\n",
    "def remove_stopwords_with_lughaat(text, sentiment_stopwords):\n",
    "\n",
    "    filtered_text = textProcessor.remove_stopwords(text)\n",
    " \n",
    "    filtered_text = \" \".join([word for word in filtered_text.split() if word not in sentiment_stopwords])\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "data_frame['clean'] = data_frame['urdu_text'].apply(\n",
    "    lambda x: remove_stopwords_with_lughaat(x, sentiment_carrying_stopwords) if pd.notnull(x) else x\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nSample Data After Stopword Removal:\")\n",
    "print(data_frame[['urdu_text', 'clean']].head()\n",
    "     \n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31801f82-bb1d-467f-b974-9577c0a6ede3",
   "metadata": {},
   "source": [
    "# Step 4: Text Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee27092c-7150-4771-8c45-61ba6479b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     positivepositivepositive لینے شادی فسادن ٹھیک ...\n",
      "1     چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...\n",
      "2     کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
      "3                                        پائین positive\n",
      "4        مراد علی شاہ بھیس ڈی آئی آئی  حامد میرpositive\n",
      "5              قابل اعتبار قاتل اعتبار negativepositive\n",
      "6                              انساں تھکا سوچوں سفر    \n",
      "7                                حامد میر ویلڈنpositive\n",
      "8     یار وچارہ ویلا ہوندا آرے ہویا ہےpositivepositi...\n",
      "9     سمجھتے سارا پاکستان بیوقوف ھے positivepositive...\n",
      "10      تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
      "11                        پائن دوبارہ فالو کرئیے   ؟ ؟ \n",
      "12    کتنی مہنگائی الو دوسو روپے درجن کدو 80روپے گز ...\n",
      "13    عشق راس آۓ negativeزخم کھاٶ گے positiveمُسکراٶ گے\n",
      "14                                        چونا positive\n",
      "15    خاتم  النبیین  محمدﷺ Surat 73 سورة المزمل Ayt ...\n",
      "16                بیچارے بیویاں ہیے تیسری ٹرائ positive\n",
      "17                پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
      "18                اللہ رحمتوں سائے مکمل صحت یاب فرمائے \n",
      "19            آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ \n",
      "20    کھوتی بچیا،تیری عزت اے،تیری قدر اے ۔ شکر بونڈ ...\n",
      "21    فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعے ن...\n",
      "22                                   لڑکی جیتی positive\n",
      "23    صدائیں درودوں رہینگی سن دل شاد گا، خدا اہلسنت ...\n",
      "24                                ووٹ بجائے ووٹر عزّت ️\n",
      "25    2004 نشئی کہا      اسٹیبلشمنٹ کتا وزیراعظم 201...\n",
      "26                       مشکل ناممکن کامران کوشش ۔ ۔ ؟ \n",
      "27          پورے ہفتے سالن روٹی کھایا کوئی حال negative\n",
      "28                                     positivepositive\n",
      "29    وھ کوئی ھو بیشک ھے ھو  کیمنا حرام ھو حق بات کا...\n",
      "30    ماضی انتہائی بے وقوف حال سمجھدار لڑکی ہوں مریم...\n",
      "31                                       آمین ثمہ آمین \n",
      "32    جیتھے کھوتی وتھے آ کھلوتی positivepositiveposi...\n",
      "33    اسمبلی ڈیزل چل اِسکو گدھا  ھے گدھے ڈیزل  ڈنڈے ...\n",
      "34    عجیب بات کامران خان ۔ پنگا گولیاں محو رقص ۔ پت...\n",
      "35                                     گڈ ناٸیٹpositive\n",
      "36    دروازے اتارتے تھپڑ لگاتے positivepositiveposit...\n",
      "37                      کلہاڑی مارنا کوئ سیکھے positive\n",
      "38          دلہن پھپھو positivepositivepositivepositive\n",
      "39    ہاہاہاہاہاہاہاہاہاہاہاہاہاہاہاہا کمینہ positiv...\n",
      "40    محمد ندیم ملک بطور عام پاکستانی بلاول زرداری د...\n",
      "41    قطری نانی ۔ ۔ بلو رانی ذلیل وقت چاہتا ۔ ۔ ۔ ۔ ...\n",
      "42    اچھا بھائیوں ویلکم لڑکی بہنوں کرا نہیںpositive...\n",
      "43              موٹی چڑیل ٹویٹ positivepositivepositive\n",
      "44           ایتھے تے جج ۔ ۔ ۔ positivepositivepositive\n",
      "45    سارا دن پاک فوج خلاف بکواس رات فوجی گل ۔ ۔ ۔ p...\n",
      "46    لگتا دیوتا پورا پاکستان  لکیروں  سہارے سوچتا ب...\n",
      "47    ہاہاہاہاہاہاہاہاہاہاہااہاہاہاہا positivepositi...\n",
      "48    ضرورت الٹی کھوپڑی بات کان سنو نکال positivepos...\n",
      "49    سنا 1 اکیلا 1 11 گیارہ ۔ تاریخ دفعہ 11 1 برباد...\n",
      "Name: cleaned_text1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "emoji_sentiment_dict = {\n",
    "    \"😊\": \"positive\", \"😢\": \"negative\", \"😂\": \"positive\", \"🤣\": \"positive\",\n",
    "    \"😎\": \"positive\", \"😡\": \"negative\", \"❤️\": \"positive\", \"💔\": \"negative\",\n",
    "    \"👍\": \"positive\", \"👎\": \"negative\", \"😭\": \"negative\", \"😜\": \"positive\",\n",
    "    \"😁\": \"positive\", \"🔥\": \"positive\", \"😐\": \"negative\"\n",
    "}\n",
    "\n",
    "\n",
    "def clean_text_with_lughaat(text, emoji_dict):\n",
    "    if not isinstance(text, str):  \n",
    "        return ''  \n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove hashtags (optional)\n",
    "    text = re.sub(r\"#\\w+\", '', text)\n",
    "    # Remove punctuations (except those in the sentiment dict)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Replace recognized emojis with their sentiment labels\n",
    "    cleaned_text = []\n",
    "    for char in text:\n",
    "        if char in emoji_sentiment_dict:\n",
    "            cleaned_text.append(emoji_sentiment_dict[char])  # Replace with sentiment label\n",
    "        elif not emoji.is_emoji(char):  # Check if it's not an emoji\n",
    "            cleaned_text.append(char)  # Keep original character\n",
    "\n",
    "    return ''.join(cleaned_text)  \n",
    "# Apply cleaning function\n",
    "data_frame['cleaned_text1'] = data_frame['clean'].apply(\n",
    "    lambda x: clean_text_with_lughaat(str(x), emoji_sentiment_dict) if pd.notnull(x) else x\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(data_frame['cleaned_text1'].head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f40cd7",
   "metadata": {},
   "source": [
    "# Step 5: Applying the filtering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5df091a9-9da9-49d8-9ec9-b203ec03be92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text1  \\\n",
      "0   positivepositivepositive لینے شادی فسادن ٹھیک ...   \n",
      "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...   \n",
      "2   کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...   \n",
      "4      مراد علی شاہ بھیس ڈی آئی آئی  حامد میرpositive   \n",
      "5            قابل اعتبار قاتل اعتبار negativepositive   \n",
      "6                            انساں تھکا سوچوں سفر       \n",
      "7                              حامد میر ویلڈنpositive   \n",
      "8   یار وچارہ ویلا ہوندا آرے ہویا ہےpositivepositi...   \n",
      "9   سمجھتے سارا پاکستان بیوقوف ھے positivepositive...   \n",
      "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive   \n",
      "11                      پائن دوبارہ فالو کرئیے   ؟ ؟    \n",
      "12  کتنی مہنگائی الو دوسو روپے درجن کدو 80روپے گز ...   \n",
      "13  عشق راس آۓ negativeزخم کھاٶ گے positiveمُسکراٶ گے   \n",
      "15  خاتم  النبیین  محمدﷺ Surat 73 سورة المزمل Ayt ...   \n",
      "16              بیچارے بیویاں ہیے تیسری ٹرائ positive   \n",
      "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative   \n",
      "18              اللہ رحمتوں سائے مکمل صحت یاب فرمائے    \n",
      "19          آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔    \n",
      "20  کھوتی بچیا،تیری عزت اے،تیری قدر اے ۔ شکر بونڈ ...   \n",
      "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعے ن...   \n",
      "\n",
      "                                        filtered_text  \n",
      "0   positivepositivepositive لینے شادی فسادن ٹھیک ...  \n",
      "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...  \n",
      "2   کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...  \n",
      "4      مراد علی شاہ بھیس ڈی آئی آئی  حامد میرpositive  \n",
      "5            قابل اعتبار قاتل اعتبار negativepositive  \n",
      "6                            انساں تھکا سوچوں سفر      \n",
      "7                              حامد میر ویلڈنpositive  \n",
      "8   یار وچارہ ویلا ہوندا آرے ہویا ہےpositivepositi...  \n",
      "9   سمجھتے سارا پاکستان بیوقوف ھے positivepositive...  \n",
      "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive  \n",
      "11                      پائن دوبارہ فالو کرئیے   ؟ ؟   \n",
      "12  کتنی مہنگائی الو دوسو روپے درجن کدو 80روپے گز ...  \n",
      "13  عشق راس آۓ negativeزخم کھاٶ گے positiveمُسکراٶ گے  \n",
      "15  خاتم  النبیین  محمدﷺ Surat 73 سورة المزمل Ayt ...  \n",
      "16              بیچارے بیویاں ہیے تیسری ٹرائ positive  \n",
      "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative  \n",
      "18              اللہ رحمتوں سائے مکمل صحت یاب فرمائے   \n",
      "19          آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔   \n",
      "20  کھوتی بچیا،تیری عزت اے،تیری قدر اے ۔ شکر بونڈ ...  \n",
      "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعے ن...  \n"
     ]
    }
   ],
   "source": [
    "def filter_short_posts(text):\n",
    "    return len(text.split()) >= 3  # Keep posts with 3 or more words\n",
    "\n",
    "# Apply the filtering function\n",
    "data_frame['filtered_text'] = data_frame['cleaned_text1'].apply(lambda x: x if filter_short_posts(x) else None)\n",
    "\n",
    "# Drop rows with None values in 'filtered_text'\n",
    "data_frame.dropna(subset=['filtered_text'], inplace=True)\n",
    "\n",
    "# Display the filtered results\n",
    "print(data_frame[['cleaned_text1', 'filtered_text']].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de01c9",
   "metadata": {},
   "source": [
    "# Replacing 'urdu_text' column with 'filtered_text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a5389a5-2a2a-40bf-88e6-97e92b3e7ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Preprocessed Urdu Text:\n",
      "                                            urdu_text\n",
      "0   positivepositivepositive لینے شادی فسادن ٹھیک ...\n",
      "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...\n",
      "2   کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
      "4      مراد علی شاہ بھیس ڈی آئی آئی  حامد میرpositive\n",
      "5            قابل اعتبار قاتل اعتبار negativepositive\n",
      "6                            انساں تھکا سوچوں سفر    \n",
      "7                              حامد میر ویلڈنpositive\n",
      "8   یار وچارہ ویلا ہوندا آرے ہویا ہےpositivepositi...\n",
      "9   سمجھتے سارا پاکستان بیوقوف ھے positivepositive...\n",
      "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
      "11                      پائن دوبارہ فالو کرئیے   ؟ ؟ \n",
      "12  کتنی مہنگائی الو دوسو روپے درجن کدو 80روپے گز ...\n",
      "13  عشق راس آۓ negativeزخم کھاٶ گے positiveمُسکراٶ گے\n",
      "15  خاتم  النبیین  محمدﷺ Surat 73 سورة المزمل Ayt ...\n",
      "16              بیچارے بیویاں ہیے تیسری ٹرائ positive\n",
      "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
      "18              اللہ رحمتوں سائے مکمل صحت یاب فرمائے \n",
      "19          آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ \n",
      "20  کھوتی بچیا،تیری عزت اے،تیری قدر اے ۔ شکر بونڈ ...\n",
      "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعے ن...\n",
      "22                                 لڑکی جیتی positive\n",
      "23  صدائیں درودوں رہینگی سن دل شاد گا، خدا اہلسنت ...\n",
      "24                              ووٹ بجائے ووٹر عزّت ️\n",
      "25  2004 نشئی کہا      اسٹیبلشمنٹ کتا وزیراعظم 201...\n",
      "26                     مشکل ناممکن کامران کوشش ۔ ۔ ؟ \n",
      "27        پورے ہفتے سالن روٹی کھایا کوئی حال negative\n",
      "29  وھ کوئی ھو بیشک ھے ھو  کیمنا حرام ھو حق بات کا...\n",
      "30  ماضی انتہائی بے وقوف حال سمجھدار لڑکی ہوں مریم...\n",
      "31                                     آمین ثمہ آمین \n",
      "32  جیتھے کھوتی وتھے آ کھلوتی positivepositiveposi...\n"
     ]
    }
   ],
   "source": [
    "# Replace 'urdu_text' column with 'filtered_text' column\n",
    "data_frame['urdu_text'] = data_frame['filtered_text']\n",
    "print(\"Final Preprocessed Urdu Text:\")\n",
    "print(data_frame[['urdu_text']].head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc66df-05b8-4d02-bcc1-f74164408667",
   "metadata": {},
   "source": [
    "# Phase 2: Stemming and Lemmatization for Urdu Text using LughaatNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed886f9",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80626c84-075c-4364-819a-f6b5ab926cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data After Stemming:\n",
      "                                           urdu_text  \\\n",
      "0  positivepositivepositive لینے شادی فسادن ٹھیک ...   \n",
      "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...   \n",
      "2  کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...   \n",
      "4     مراد علی شاہ بھیس ڈی آئی آئی  حامد میرpositive   \n",
      "5           قابل اعتبار قاتل اعتبار negativepositive   \n",
      "\n",
      "                                        stemmed_text  \n",
      "0  positivepositivepositive لینہ شادی فسادن ٹھیک ...  \n",
      "1  چل مہمانا کھانا سرو چڑیل چاچی نا دسدی آں میںpo...  \n",
      "2  کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...  \n",
      "4      مراد علی شاہ بھیس ڈی آئی آئی حامد میرpositive  \n",
      "5             قابل اعتبر قاتل اعتبر negativepositive  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def apply_stemming(text):\n",
    "    stemmed_text = textProcessor.urdu_stemmer(text)\n",
    "    return stemmed_text\n",
    "\n",
    "# Apply stemming to the 'cleaned_text' column\n",
    "data_frame['stemmed_text'] = data_frame['urdu_text'].apply(lambda x: apply_stemming(str(x)) if pd.notnull(x) else x)\n",
    "\n",
    "# Display the first few rows after stemming\n",
    "print(\"\\nSample Data After Stemming:\")\n",
    "print(data_frame[['urdu_text', 'stemmed_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7127406e-b6fc-407f-a7eb-32a58e8ca29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Preprocessed Urdu Text:\n",
      "                                            urdu_text\n",
      "0   positivepositivepositive لینہ شادی فسادن ٹھیک ...\n",
      "1   چل مہمانا کھانا سرو چڑیل چاچی نا دسدی آں میںpo...\n",
      "2   کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
      "4       مراد علی شاہ بھیس ڈی آئی آئی حامد میرpositive\n",
      "5              قابل اعتبر قاتل اعتبر negativepositive\n",
      "6                                 انساں تھکا سوچا سفر\n",
      "7                              حامد میر ویلڈنpositive\n",
      "8   یار وچارہ ویلا ہوندا آرہ ہویا ہےpositivepositi...\n",
      "9   سمجھتہ سارا پاکستن بیوقوف ھہ positivepositivep...\n",
      "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
      "11                          پائن دوبرہ فالو کرئیہ ؟ ؟\n",
      "12  کتنی مہنگائی الو دوسو روپہ درجن کدو 80روپہ گز ...\n",
      "13  عشق راس آۓ negativeزخم کھاٶ گہ positiveمُسکراٶ گہ\n",
      "15  خاتم النبیین محمدﷺ Surat 73 سوره المزمل Ayt 20...\n",
      "16                بیچارہ بیوی ہیہ تیسری ٹرائ positive\n",
      "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
      "18                 اللہ رحمت سائہ مکمل صحت یاب فرمائہ\n",
      "19           آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔\n",
      "20  کھوتی بچیا،تیری عزت اہ،تیری قدر اہ ۔ شکر بونڈ ...\n",
      "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعہ ن...\n",
      "22                                 لڑکی جیتی positive\n",
      "23  صدائا درودا رہینگی سن دل شاد گا، خدا اہلسنت آب...\n",
      "24                              ووٹ بجائہ ووٹر عزّت ️\n",
      "25  2004 نشئی کہا اسٹیبلشمنٹ کت وزیراعظم 2018 کتہ ...\n",
      "26                      مشکل ناممکن کامران کوشش ۔ ۔ ؟\n",
      "27        پورہ ہفتہ سالن روٹی کھایا کوئی حال negative\n",
      "29  وھ کوئی ھو بیشک ھہ ھو کیمنا حرام ھو حق به کامر...\n",
      "30  ماضی انتہائی بہ وقوف حال سمجھدار لڑکی ہا مریم ...\n",
      "31                                      آمین ثمہ آمین\n",
      "32  جیتھہ کھوتی وتھہ آ کھلوتی positivepositiveposi...\n"
     ]
    }
   ],
   "source": [
    "data_frame['urdu_text'] = data_frame['stemmed_text']\n",
    "print(\"Final Preprocessed Urdu Text:\")\n",
    "print(data_frame[['urdu_text']].head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b17681",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cb2377a-15e9-42af-834e-173a3c2d2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data After Lemmatization:\n",
      "                                        stemmed_text  \\\n",
      "0  positivepositivepositive لینہ شادی فسادن ٹھیک ...   \n",
      "1  چل مہمانا کھانا سرو چڑیل چاچی نا دسدی آں میںpo...   \n",
      "2  کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...   \n",
      "4      مراد علی شاہ بھیس ڈی آئی آئی حامد میرpositive   \n",
      "5             قابل اعتبر قاتل اعتبر negativepositive   \n",
      "\n",
      "                                     lemmatized_text  \n",
      "0  positivepositivepositive لینہ شادی فسادن ٹھیک ...  \n",
      "1  چلنا مہمانا کھا سرا چڑیل چاچی نا دسدی آں میںpo...  \n",
      "2  کامران خان دن بھریہ زمہ داری لگنا جانا اپوزیشن...  \n",
      "4      مراد علی شاہ بھیس ڈی آئی آئی حامد میرpositive  \n",
      "5             قابل اعتبر قاتل اعتبر negativepositive  \n",
      "Final Preprocessed Urdu Text:\n",
      "                                            urdu_text\n",
      "0   positivepositivepositive لینہ شادی فسادن ٹھیک ...\n",
      "1   چلنا مہمانا کھا سرا چڑیل چاچی نا دسدی آں میںpo...\n",
      "2   کامران خان دن بھریہ زمہ داری لگنا جانا اپوزیشن...\n",
      "4       مراد علی شاہ بھیس ڈی آئی آئی حامد میرpositive\n",
      "5              قابل اعتبر قاتل اعتبر negativepositive\n",
      "6                               انساں تھکنا سوچنا سفر\n",
      "7                              حامد میر ویلڈنpositive\n",
      "8   یار وچارہ ویلا ہوندا آرہ ہویا ہےpositivepositi...\n",
      "9   سمجھتہ سارا پاکستن بیوقوف ھہ positivepositivep...\n",
      "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
      "11                          پائن دوبرہ فالو کرئیہ ؟ ؟\n",
      "12  کتنا مہنگائی الہ دوسو روپہ درجن کدہ 80روپہ گز ...\n",
      "13  عشق راس آۓ negativeزخم کھاٶ گہ positiveمُسکراٶ گہ\n",
      "15  خاتم النبیین محمدﷺ Surat 73 سوره المزمل Ayt 20...\n",
      "16                بیچارہ بیوی ہیہ تیسری ٹرائ positive\n",
      "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
      "18                 اللہ رحمت سائہ مکمل صحت یاب فرمائہ\n",
      "19           آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔\n",
      "20  کھونا بچیا،تیری عزت اہ،تیری قدر اہ ۔ شکر بونڈ ...\n",
      "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعہ ن...\n",
      "22                                 لڑکی جینا positive\n",
      "23  صدائا درودا رہینگی سننا دل شاد گا، خدا اہلسنت ...\n",
      "24                              ووٹ بجائہ ووٹر عزّت ️\n",
      "25  2004 نشئی کہنا اسٹیبلشمنٹ کت وزیراعظم 2018 کتہ...\n",
      "26                      مشکل ناممکن کامران کوشش ۔ ۔ ؟\n",
      "27        پورہ ہفتہ سالن روٹی کھانا کوئی حال negative\n",
      "29  وھ کوئی ھو بیشک ھہ ھو کیمنا حرام ھو حق به کامر...\n",
      "30  ماضی انتہائی بہ وقوف حال سمجھدار لڑکی ہا مریم ...\n",
      "31                                      آمین ثمہ آمین\n",
      "32  جیتھہ کھونا وتھہ آنا کھلوتی positivepositivepo...\n"
     ]
    }
   ],
   "source": [
    "def apply_lemmatization(text):\n",
    "    lemmatized_text = textProcessor.lemmatize_sentence(text)\n",
    "    return lemmatized_text\n",
    "\n",
    "# Apply lemmatization to the 'stemmed_text' column\n",
    "data_frame['lemmatized_text'] = data_frame['stemmed_text'].apply(lambda x: apply_lemmatization(str(x)) if pd.notnull(x) else x)\n",
    "\n",
    "# Display the first few rows after lemmatization\n",
    "print(\"\\nSample Data After Lemmatization:\")\n",
    "print(data_frame[['stemmed_text', 'lemmatized_text']].head())\n",
    "\n",
    "data_frame['urdu_text'] = data_frame['lemmatized_text']\n",
    "print(\"Final Preprocessed Urdu Text:\")\n",
    "print(data_frame[['urdu_text']].head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a77d91-93f9-4236-ae87-acbbd24f3e3c",
   "metadata": {},
   "source": [
    "# Phase 3: Feature Extraction from Urdu Text using LughaatNLP and Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5faaae16-aacc-4df3-bef6-0f7980ea5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eaf75b-a66f-4f50-8019-6c4ea00befec",
   "metadata": {},
   "source": [
    "# Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4a0d2e1-f9dc-4e3c-ac16-9aa886280db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data After Tokenization:\n",
      "                                           urdu_text  \\\n",
      "0  positivepositivepositive لینہ شادی فسادن ٹھیک ...   \n",
      "1  چلنا مہمانا کھا سرا چڑیل چاچی نا دسدی آں میںpo...   \n",
      "2  کامران خان دن بھریہ زمہ داری لگنا جانا اپوزیشن...   \n",
      "4      مراد علی شاہ بھیس ڈی آئی آئی حامد میرpositive   \n",
      "5             قابل اعتبر قاتل اعتبر negativepositive   \n",
      "\n",
      "                                      tokenized_text  \n",
      "0                    [لینہ, شادی, فسادن, ٹھیک, کوجی]  \n",
      "1  [چلنا, مہمانا, کھا, سرا, چڑیل, چاچی, نا, دسدی,...  \n",
      "2  [کامران, خان, دن, بھریہ, زمہ, داری, لگنا, جانا...  \n",
      "4    [مراد, علی, شاہ, بھیس, ڈی, آئی, آئی, حامد, میر]  \n",
      "5                         [قابل, اعتبر, قاتل, اعتبر]  \n"
     ]
    }
   ],
   "source": [
    "# Function to tokenize the text using LughaatNLP's urdu_tokenize function\n",
    "def tokenize_text(text):\n",
    "    tokens = textProcessor.urdu_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization to the 'lemmatized_text' column\n",
    "data_frame['tokenized_text'] = data_frame['lemmatized_text'].apply(lambda x: tokenize_text(str(x)) if pd.notnull(x) else x)\n",
    "\n",
    "# Display the first few rows after tokenization\n",
    "print(\"\\nSample Data After Tokenization:\")\n",
    "print(data_frame[['urdu_text', 'tokenized_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e5722-195e-4fc2-8359-f49b103ef465",
   "metadata": {},
   "source": [
    "# Step 2: TF-IDF (Term Frequency-Inverse Document Frequency) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a137e7c-6c53-4c90-833c-71d4a69ce425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Words with Highest TF-IDF Scores:\n",
      "۔                           0.133195\n",
      "positive                    0.080712\n",
      "positivepositive            0.035554\n",
      "positivepositivepositive    0.028631\n",
      "؟                           0.028484\n",
      "اللہ                        0.027203\n",
      "کوئی                        0.027128\n",
      "خان                         0.025684\n",
      "به                          0.023354\n",
      "ھہ                          0.022596\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the TF-IDF Vectorizer for Urdu text\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), max_features=100)\n",
    "\n",
    "# Fit and transform the lemmatized text to extract TF-IDF features\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data_frame['urdu_text'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for better readability\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the top 10 words with the highest average TF-IDF scores\n",
    "top_tfidf_words = tfidf_df.mean().sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop 10 Words with Highest TF-IDF Scores:\")\n",
    "print(top_tfidf_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc4fbc-3610-42f0-85f7-c63d498e2650",
   "metadata": {},
   "source": [
    "# Step 3: Word2Vec Model Training and Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2830924e-c503-4799-ac33-c4aa6ba1a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Words Most Similar to 'اچھا':\n",
      "بچہ: 0.9874\n",
      "حال: 0.9860\n",
      "آئہ: 0.9840\n",
      "سوچ: 0.9822\n",
      "بت: 0.9810\n"
     ]
    }
   ],
   "source": [
    "# Prepare the tokenized text for Word2Vec training\n",
    "tokenized_texts =data_frame['tokenized_text'].tolist()\n",
    "\n",
    "# Train the Word2Vec model using the tokenized text\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=8, min_count=2, workers=4)\n",
    "\n",
    "# List the top 5 words most similar to the word \"اچھا\" (good)\n",
    "try:\n",
    "    similar_words = word2vec_model.wv.most_similar(\"اچھا\", topn=5)\n",
    "    print(\"\\nTop 5 Words Most Similar to 'اچھا':\")\n",
    "    for word, similarity in similar_words:\n",
    "        print(f\"{word}: {similarity:.4f}\")\n",
    "except KeyError:\n",
    "    print(\"\\nThe word 'اچھا' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12359fe8-306c-4292-b5c9-7d0c1ea77c2c",
   "metadata": {},
   "source": [
    "# Phase 4: N-grams Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49cb5041-7368-4d2b-8b33-332b7181ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "tokenized_texts = data_frame['tokenized_text'].tolist()  \n",
    "\n",
    "# Flatten the tokenized texts for unigram analysis\n",
    "all_words = [word for tokens in tokenized_texts for word in tokens]\n",
    "\n",
    "# Unigrams\n",
    "unigram_freq = Counter(all_words)\n",
    "\n",
    "# Bigrams\n",
    "bigram_list = [list(ngrams(tokens, 2)) for tokens in tokenized_texts]\n",
    "bigrams = [bigram for sublist in bigram_list for bigram in sublist]  # Flatten\n",
    "bigram_freq = Counter(bigrams)\n",
    "\n",
    "# Trigrams\n",
    "trigram_list = [list(ngrams(tokens, 3)) for tokens in tokenized_texts]\n",
    "trigrams = [trigram for sublist in trigram_list for trigram in sublist]  # Flatten\n",
    "trigram_freq = Counter(trigrams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f61dd5",
   "metadata": {},
   "source": [
    "# Get the top 10 most common unigrams, bigrams, and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecda4038-8c72-4605-8510-423645783841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Unigrams:\n",
      "۔: 11547\n",
      "؟: 1580\n",
      "️: 1560\n",
      "کوئی: 1174\n",
      "خان: 1172\n",
      "ھہ: 1067\n",
      "اللہ: 989\n",
      "به: 976\n",
      "پاکستن: 859\n",
      "سندھ: 815\n",
      "\n",
      "Top 10 Bigrams:\n",
      "('۔', '۔'): 4685\n",
      "('عمران', 'خان'): 508\n",
      "('؟', '؟'): 496\n",
      "('نواز', 'شریف'): 448\n",
      "('\\u200d', '️'): 332\n",
      "('سندھ', 'پولیس'): 307\n",
      "('️', '️'): 260\n",
      "('آرمی', 'چیف'): 223\n",
      "('کیپٹن', 'صفدر'): 179\n",
      "('اردو', 'زبن'): 172\n",
      "\n",
      "Top 10 Trigrams:\n",
      "('۔', '۔', '۔'): 2302\n",
      "('؟', '؟', '؟'): 234\n",
      "('\\u2066', '️', '\\u2069'): 131\n",
      "('️', '️', '️'): 121\n",
      "('\\u200d', '️', '\\u200d'): 117\n",
      "('️', '\\u200d', '️'): 116\n",
      "('پینا', 'ٹی', 'آئی'): 114\n",
      "('پینا', 'ڈی', 'ایم'): 88\n",
      "('صلی', 'اللہ', 'علیہ'): 88\n",
      "('جزاک', 'اللہ', 'خیر'): 74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "top_unigrams = unigram_freq.most_common(10)\n",
    "top_bigrams = bigram_freq.most_common(10)\n",
    "top_trigrams = trigram_freq.most_common(10)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nTop 10 Unigrams:\")\n",
    "for word, freq in top_unigrams:\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nTop 10 Bigrams:\")\n",
    "for bigram, freq in top_bigrams:\n",
    "    print(f\"{bigram}: {freq}\")\n",
    "\n",
    "print(\"\\nTop 10 Trigrams:\")\n",
    "for trigram, freq in top_trigrams:\n",
    "    print(f\"{trigram}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c643e-53cd-48ad-85fe-cf644f73e182",
   "metadata": {},
   "source": [
    "# Phase 5: Sentiment Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e783e0b-92ac-419c-b0df-bb0d1bf72529",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75d09847-72c6-45e2-98b8-117c58448f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7126\n",
      "Precision: 0.7428\n",
      "Recall: 0.7095\n",
      "F1 Score: 0.7258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'labels' column has the sentiment labels (1 for positive, 0 for negative/neutral)\n",
    "X = tfidf_matrix\n",
    "y = data_frame['is_sarcastic']  # replace with your actual label column\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2cfba-89dd-4dc6-b4c6-e6d9f35b8cbf",
   "metadata": {},
   "source": [
    "Evaluation Summary\n",
    "Accuracy: 71.26%\n",
    "The model correctly classified approximately 71 out of 100 instances in the validation set.\n",
    "Precision: 74.28%\n",
    "Of all the positive predictions made by the model, 74.28% were accurate, indicating a reduced number of false positives compared to previous models.\n",
    "Recall: 70.95%\n",
    "The model identified 70.95% of the actual positive sentiments, showing it maintains good coverage of relevant instances.\n",
    "F1 Score: 72.58%\n",
    "This score reflects a balance between precision and recall, indicating an overall improvement in performance compared to earlier results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80327b54-78a4-49a8-b37b-56252690deb7",
   "metadata": {},
   "source": [
    "# 1. Evaluation\n",
    "#Model Performance\n",
    "The sentiment analysis model achieved an accuracy of 71.26%, with precision at 74.28%, recall at 70.95%, and an F1 score of 72.58%. These metrics indicate that the model is fairly balanced, with a good ability to identify positive sentiments but showing some difficulty with negative sentiments. For instance, it may misinterpret nuanced phrases like “یہ بہت برا ہے” (This is very bad) if it fails to grasp the context or the negation, leading to inaccuracies in sentiment classification.\n",
    "# Challenges with Stemming and Lemmatization\n",
    "Stemming and lemmatization are particularly challenging in Urdu due to the language’s complex morphology. Words can change forms based on gender, plurality, or tense. For example, the word \"اچھا\" (good) can appear as \"اچھی\" (good, feminine) and \"اچھے\" (good, plural). This variation can confuse the model, especially in contexts like “یہ اچھا نہیں ہے” (This is not good), where understanding negation is crucial for accurate sentiment analysis. If the model does not recognize these morphological changes, it may misclassify the overall sentiment.\n",
    "# Areas for Improvement\n",
    "To enhance performance, we should focus on refining preprocessing techniques, such as applying more advanced stemming algorithms that accommodate the richness of Urdu. Implementing methods like analysis and utilizing pre-trained models that consider context could significantly improve sentiment classification accuracy, especially for complex sentence structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a4c6d0-6ee0-42be-933e-937ef669c5e0",
   "metadata": {},
   "source": [
    "# 2. Challenges in Urdu Sentiment Analysis\n",
    "# Complex Morphology\n",
    "Urdu’s intricate word forms pose significant challenges for stemming and lemmatization. For instance, the root “چلنا” (to walk) can manifest as “چلتا” (masculine), “چلتی” (feminine), and “چلیں گے” (will walk, plural). This complexity can lead to context loss during analysis, misclassifying sentiments in sentences such as “وہ ہمیشہ چلتی رہتی ہے” (She keeps walking always), where the sentiment may hinge on understanding the specific word forms used.\n",
    "# Colloquial Language\n",
    "The informal and colloquial nature of language used on social media introduces slang and abbreviations that complicate sentiment analysis. Phrases like “بہت زبردست” (very awesome) or “کمال ہے” (it's amazing) might not align with formal language models. Additionally, expressions such as “نہیں یار” (no man) can convey sarcasm but may be misinterpreted by the model as literal negation, leading to incorrect sentiment classification.\n",
    "# Noisy Data\n",
    "Social media platforms are filled with noisy data, including emojis, misspellings, and unconventional grammar. For example, a post containing “یہ تو بہت 😂 ہے” (This is so funny) may confuse the model due to the emotional context of the emoji. Typos, such as “برا” (bad) being written as “براہ” or “بڑا” (big), can further hinder the model's ability to extract clear sentiment signals.\n",
    "# Optimizing the NLP Pipeline\n",
    "To enhance Urdu sentiment analysis, we should implement better data normalization techniques, including spell-checking algorithms and expanding the training dataset to encompass a wider variety of colloquial expressions. Utilizing advanced language models, like transformers specifically designed for Urdu, can also capture contextual meanings more effectively. By addressing these challenges and adopting these strategies, we can significantly improve the accuracy and robustness of sentiment analysis in this rich language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe7684-22b2-421b-93c5-4dd276574936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
